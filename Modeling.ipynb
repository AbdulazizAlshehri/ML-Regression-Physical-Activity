{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import patsy\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet, LinearRegression\n",
    "from sklearn.model_selection import (cross_val_score, train_test_split, KFold, GridSearchCV)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import files & Merge\n",
    "\n",
    "We used four datasets \n",
    "- Steps extracted from iphone Health app (Preparing_Data.ipynb) (33k records)\n",
    "- Sleep processed from steps (Preparing_Data.ipynb) (1200 daily record)\n",
    "- Calendar scrapped from two websites (Web_Scrapping_Calendar.ipynb & Web_Scrapping_Schools.ipynb) (14600 records)\n",
    "- Weather scrapped from website "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Steps0 = pd.read_csv(\"Steps.csv\")\n",
    "Calendar = pd.read_csv(\"Calendar.csv\")\n",
    "Sleep = pd.read_csv(\"Sleep_Schedule.csv\")\n",
    "Weather = pd.read_csv(\"weather.csv\")\n",
    "\n",
    "#Weather['date'] = pd.to_datetime(Weather['date'])\n",
    "\n",
    "Sleep.columns = Sleep.columns.str.strip()\n",
    "Calendar.columns = Calendar.columns.str.strip()\n",
    "\n",
    "\n",
    "#Calendar columns we want \n",
    "Weather = Weather[['date','temp_min','temp_max','is_rain']]\n",
    "Calendar = Calendar[['Date','AD_Month','AH_Month',\"Long_Vacation\",\"Short_Vacation\",\"Ramadan\",\"Sch_Eid_Fatr\",\"National_Day\",\"National_Day_Ext\",\"AD_WeekdayNum\"]]\n",
    "Steps0 = Steps0[[\"Date\",\"Steps\"]]\n",
    "Sleep = Sleep[['Date','Woke_Hour']]\n",
    "\n",
    "\n",
    "\n",
    "Merged = pd.merge(Steps0,Calendar,how=\"left\",on=\"Date\")\n",
    "Merged = pd.merge(Merged,Sleep,how='left',on=\"Date\")\n",
    "Merged = pd.merge(Merged,Weather,how='left',left_on='Date',right_on='date')\n",
    "Merged.sort_values('Date',inplace=True)\n",
    "#delete unneeded columns\n",
    "del Merged['date']\n",
    "\n",
    "Merged['is_rain'] = Merged['is_rain'].astype('int')\n",
    "Merged = Merged.sort_values(\"Date\")\n",
    "#save Merged file for EDA\n",
    "Merged.to_csv(\"Merged.csv\")\n",
    "# remove date column\n",
    "\n",
    "Merged = Merged.iloc[:,1:]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Steps</th>\n",
       "      <th>AD_Month</th>\n",
       "      <th>AH_Month</th>\n",
       "      <th>Long_Vacation</th>\n",
       "      <th>Short_Vacation</th>\n",
       "      <th>Ramadan</th>\n",
       "      <th>Sch_Eid_Fatr</th>\n",
       "      <th>National_Day</th>\n",
       "      <th>National_Day_Ext</th>\n",
       "      <th>AD_WeekdayNum</th>\n",
       "      <th>Woke_Hour</th>\n",
       "      <th>temp_min</th>\n",
       "      <th>temp_max</th>\n",
       "      <th>is_rain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3140</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>86</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9810</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>88</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6551</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>90</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6107</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>88</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2569</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>86</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>4454</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>73</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>3702</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>73</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>3939</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>77</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>2847</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>77</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>132</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>77</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1207 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Steps  AD_Month  AH_Month  Long_Vacation  Short_Vacation  Ramadan  \\\n",
       "0      3140         6         9              1               0        1   \n",
       "1      9810         6         9              1               0        1   \n",
       "2      6551         6         9              1               0        1   \n",
       "3      6107         6         9              1               0        1   \n",
       "4      2569         6         9              1               0        1   \n",
       "...     ...       ...       ...            ...             ...      ...   \n",
       "1202   4454         9         2              0               0        0   \n",
       "1203   3702         9         2              0               0        0   \n",
       "1204   3939         9         2              0               0        0   \n",
       "1205   2847         9         2              0               0        0   \n",
       "1206    132         9         2              0               0        0   \n",
       "\n",
       "      Sch_Eid_Fatr  National_Day  National_Day_Ext  AD_WeekdayNum  Woke_Hour  \\\n",
       "0                0             0                 0              5         18   \n",
       "1                0             0                 0              6         20   \n",
       "2                0             0                 0              0          6   \n",
       "3                0             0                 0              1          6   \n",
       "4                0             0                 0              2          6   \n",
       "...            ...           ...               ...            ...        ...   \n",
       "1202             0             0                 0              3          3   \n",
       "1203             0             0                 0              4          6   \n",
       "1204             0             0                 0              5          8   \n",
       "1205             0             0                 1              6          4   \n",
       "1206             0             0                 1              0         23   \n",
       "\n",
       "      temp_min  temp_max  is_rain  \n",
       "0           86       111        0  \n",
       "1           88       113        0  \n",
       "2           90       111        0  \n",
       "3           88       113        0  \n",
       "4           86       113        0  \n",
       "...        ...       ...      ...  \n",
       "1202        73       100        0  \n",
       "1203        73       100        0  \n",
       "1204        77       104        0  \n",
       "1205        77       102        0  \n",
       "1206        77       100        0  \n",
       "\n",
       "[1207 rows x 14 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## correlation matrix,  and pair plot\n",
    "Merged.corr()[\"Steps\"]\n",
    "sns.heatmap(Merged.corr(), cmap=\"seismic\", annot=False, vmin=-1, vmax=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Lag values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Steps</th>\n",
       "      <th>AD_Month</th>\n",
       "      <th>AH_Month</th>\n",
       "      <th>Long_Vacation</th>\n",
       "      <th>Short_Vacation</th>\n",
       "      <th>Ramadan</th>\n",
       "      <th>Sch_Eid_Fatr</th>\n",
       "      <th>National_Day</th>\n",
       "      <th>National_Day_Ext</th>\n",
       "      <th>AD_WeekdayNum</th>\n",
       "      <th>...</th>\n",
       "      <th>temp_max</th>\n",
       "      <th>is_rain</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Lag6</th>\n",
       "      <th>Lag7</th>\n",
       "      <th>Lag8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3811</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>1756.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>2283.0</td>\n",
       "      <td>2569.0</td>\n",
       "      <td>6107.0</td>\n",
       "      <td>6551.0</td>\n",
       "      <td>9810.0</td>\n",
       "      <td>3140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2202</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>3811.0</td>\n",
       "      <td>1756.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>2283.0</td>\n",
       "      <td>2569.0</td>\n",
       "      <td>6107.0</td>\n",
       "      <td>6551.0</td>\n",
       "      <td>9810.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11535</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>2202.0</td>\n",
       "      <td>3811.0</td>\n",
       "      <td>1756.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>2283.0</td>\n",
       "      <td>2569.0</td>\n",
       "      <td>6107.0</td>\n",
       "      <td>6551.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10248</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>11535.0</td>\n",
       "      <td>2202.0</td>\n",
       "      <td>3811.0</td>\n",
       "      <td>1756.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>2283.0</td>\n",
       "      <td>2569.0</td>\n",
       "      <td>6107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10022</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>10248.0</td>\n",
       "      <td>11535.0</td>\n",
       "      <td>2202.0</td>\n",
       "      <td>3811.0</td>\n",
       "      <td>1756.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>2283.0</td>\n",
       "      <td>2569.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>4454</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>5448.0</td>\n",
       "      <td>2739.0</td>\n",
       "      <td>2668.0</td>\n",
       "      <td>4474.0</td>\n",
       "      <td>4337.0</td>\n",
       "      <td>980.0</td>\n",
       "      <td>2310.0</td>\n",
       "      <td>2378.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>3702</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>4454.0</td>\n",
       "      <td>5448.0</td>\n",
       "      <td>2739.0</td>\n",
       "      <td>2668.0</td>\n",
       "      <td>4474.0</td>\n",
       "      <td>4337.0</td>\n",
       "      <td>980.0</td>\n",
       "      <td>2310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>3939</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>3702.0</td>\n",
       "      <td>4454.0</td>\n",
       "      <td>5448.0</td>\n",
       "      <td>2739.0</td>\n",
       "      <td>2668.0</td>\n",
       "      <td>4474.0</td>\n",
       "      <td>4337.0</td>\n",
       "      <td>980.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>2847</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>3939.0</td>\n",
       "      <td>3702.0</td>\n",
       "      <td>4454.0</td>\n",
       "      <td>5448.0</td>\n",
       "      <td>2739.0</td>\n",
       "      <td>2668.0</td>\n",
       "      <td>4474.0</td>\n",
       "      <td>4337.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>132</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>2847.0</td>\n",
       "      <td>3939.0</td>\n",
       "      <td>3702.0</td>\n",
       "      <td>4454.0</td>\n",
       "      <td>5448.0</td>\n",
       "      <td>2739.0</td>\n",
       "      <td>2668.0</td>\n",
       "      <td>4474.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1199 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Steps  AD_Month  AH_Month  Long_Vacation  Short_Vacation  Ramadan  \\\n",
       "8      3811         6         9              1               0        1   \n",
       "9      2202         6         9              1               0        1   \n",
       "10    11535         6         9              1               0        1   \n",
       "11    10248         6         9              1               0        1   \n",
       "12    10022         6         9              1               0        1   \n",
       "...     ...       ...       ...            ...             ...      ...   \n",
       "1202   4454         9         2              0               0        0   \n",
       "1203   3702         9         2              0               0        0   \n",
       "1204   3939         9         2              0               0        0   \n",
       "1205   2847         9         2              0               0        0   \n",
       "1206    132         9         2              0               0        0   \n",
       "\n",
       "      Sch_Eid_Fatr  National_Day  National_Day_Ext  AD_WeekdayNum  ...  \\\n",
       "8                0             0                 0              6  ...   \n",
       "9                0             0                 0              0  ...   \n",
       "10               0             0                 0              1  ...   \n",
       "11               0             0                 0              2  ...   \n",
       "12               0             0                 0              3  ...   \n",
       "...            ...           ...               ...            ...  ...   \n",
       "1202             0             0                 0              3  ...   \n",
       "1203             0             0                 0              4  ...   \n",
       "1204             0             0                 0              5  ...   \n",
       "1205             0             0                 1              6  ...   \n",
       "1206             0             0                 1              0  ...   \n",
       "\n",
       "      temp_max  is_rain     Lag1     Lag2    Lag3    Lag4    Lag5    Lag6  \\\n",
       "8          111        0   1756.0    743.0  2283.0  2569.0  6107.0  6551.0   \n",
       "9          109        0   3811.0   1756.0   743.0  2283.0  2569.0  6107.0   \n",
       "10         109        0   2202.0   3811.0  1756.0   743.0  2283.0  2569.0   \n",
       "11         106        0  11535.0   2202.0  3811.0  1756.0   743.0  2283.0   \n",
       "12         104        0  10248.0  11535.0  2202.0  3811.0  1756.0   743.0   \n",
       "...        ...      ...      ...      ...     ...     ...     ...     ...   \n",
       "1202       100        0   5448.0   2739.0  2668.0  4474.0  4337.0   980.0   \n",
       "1203       100        0   4454.0   5448.0  2739.0  2668.0  4474.0  4337.0   \n",
       "1204       104        0   3702.0   4454.0  5448.0  2739.0  2668.0  4474.0   \n",
       "1205       102        0   3939.0   3702.0  4454.0  5448.0  2739.0  2668.0   \n",
       "1206       100        0   2847.0   3939.0  3702.0  4454.0  5448.0  2739.0   \n",
       "\n",
       "        Lag7    Lag8  \n",
       "8     9810.0  3140.0  \n",
       "9     6551.0  9810.0  \n",
       "10    6107.0  6551.0  \n",
       "11    2569.0  6107.0  \n",
       "12    2283.0  2569.0  \n",
       "...      ...     ...  \n",
       "1202  2310.0  2378.0  \n",
       "1203   980.0  2310.0  \n",
       "1204  4337.0   980.0  \n",
       "1205  4474.0  4337.0  \n",
       "1206  2668.0  4474.0  \n",
       "\n",
       "[1199 rows x 22 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate lag1 to lag 8  for time-series regression\n",
    "for i in range(1,9):\n",
    "    Merged['Lag'+str(i)] = Merged['Steps'].shift(i)\n",
    "\n",
    "\n",
    "Merged = Merged.dropna()\n",
    "Merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Steps</th>\n",
       "      <th>AD_Month</th>\n",
       "      <th>AH_Month</th>\n",
       "      <th>Long_Vacation</th>\n",
       "      <th>Short_Vacation</th>\n",
       "      <th>Ramadan</th>\n",
       "      <th>Sch_Eid_Fatr</th>\n",
       "      <th>National_Day</th>\n",
       "      <th>National_Day_Ext</th>\n",
       "      <th>AD_WeekdayNum</th>\n",
       "      <th>...</th>\n",
       "      <th>temp_max</th>\n",
       "      <th>is_rain</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Lag6</th>\n",
       "      <th>Lag7</th>\n",
       "      <th>Lag8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.077199</td>\n",
       "      <td>-0.181938</td>\n",
       "      <td>0.650276</td>\n",
       "      <td>1.493300</td>\n",
       "      <td>-0.243183</td>\n",
       "      <td>3.427173</td>\n",
       "      <td>-0.142858</td>\n",
       "      <td>-0.050063</td>\n",
       "      <td>-0.139791</td>\n",
       "      <td>1.497814</td>\n",
       "      <td>...</td>\n",
       "      <td>1.077436</td>\n",
       "      <td>-0.185698</td>\n",
       "      <td>-0.552813</td>\n",
       "      <td>-0.862393</td>\n",
       "      <td>-0.390251</td>\n",
       "      <td>-0.302354</td>\n",
       "      <td>0.780624</td>\n",
       "      <td>0.916101</td>\n",
       "      <td>1.909126</td>\n",
       "      <td>-0.129858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.415612</td>\n",
       "      <td>-0.181938</td>\n",
       "      <td>0.650276</td>\n",
       "      <td>1.493300</td>\n",
       "      <td>-0.243183</td>\n",
       "      <td>3.427173</td>\n",
       "      <td>-0.142858</td>\n",
       "      <td>-0.050063</td>\n",
       "      <td>-0.139791</td>\n",
       "      <td>-1.497814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.952312</td>\n",
       "      <td>-0.185698</td>\n",
       "      <td>0.076810</td>\n",
       "      <td>-0.552115</td>\n",
       "      <td>-0.861920</td>\n",
       "      <td>-0.389947</td>\n",
       "      <td>-0.302709</td>\n",
       "      <td>0.780178</td>\n",
       "      <td>0.912927</td>\n",
       "      <td>1.909052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.442935</td>\n",
       "      <td>-0.181938</td>\n",
       "      <td>0.650276</td>\n",
       "      <td>1.493300</td>\n",
       "      <td>-0.243183</td>\n",
       "      <td>3.427173</td>\n",
       "      <td>-0.142858</td>\n",
       "      <td>-0.050063</td>\n",
       "      <td>-0.139791</td>\n",
       "      <td>-0.998542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.952312</td>\n",
       "      <td>-0.185698</td>\n",
       "      <td>-0.416165</td>\n",
       "      <td>0.077325</td>\n",
       "      <td>-0.551660</td>\n",
       "      <td>-0.861598</td>\n",
       "      <td>-0.390282</td>\n",
       "      <td>-0.302927</td>\n",
       "      <td>0.777207</td>\n",
       "      <td>0.912829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.048748</td>\n",
       "      <td>-0.181938</td>\n",
       "      <td>0.650276</td>\n",
       "      <td>1.493300</td>\n",
       "      <td>-0.243183</td>\n",
       "      <td>3.427173</td>\n",
       "      <td>-0.142858</td>\n",
       "      <td>-0.050063</td>\n",
       "      <td>-0.139791</td>\n",
       "      <td>-0.499271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.764625</td>\n",
       "      <td>-0.185698</td>\n",
       "      <td>2.443333</td>\n",
       "      <td>-0.415506</td>\n",
       "      <td>0.077743</td>\n",
       "      <td>-0.551350</td>\n",
       "      <td>-0.861828</td>\n",
       "      <td>-0.390481</td>\n",
       "      <td>-0.304276</td>\n",
       "      <td>0.777105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.979528</td>\n",
       "      <td>-0.181938</td>\n",
       "      <td>0.650276</td>\n",
       "      <td>1.493300</td>\n",
       "      <td>-0.243183</td>\n",
       "      <td>3.427173</td>\n",
       "      <td>-0.142858</td>\n",
       "      <td>-0.050063</td>\n",
       "      <td>-0.139791</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.639501</td>\n",
       "      <td>-0.185698</td>\n",
       "      <td>2.049015</td>\n",
       "      <td>2.443160</td>\n",
       "      <td>-0.415059</td>\n",
       "      <td>0.078030</td>\n",
       "      <td>-0.551649</td>\n",
       "      <td>-0.861929</td>\n",
       "      <td>-0.391699</td>\n",
       "      <td>-0.304404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>0.274140</td>\n",
       "      <td>0.720727</td>\n",
       "      <td>-1.287162</td>\n",
       "      <td>-0.669099</td>\n",
       "      <td>-0.243183</td>\n",
       "      <td>-0.291542</td>\n",
       "      <td>-0.142858</td>\n",
       "      <td>-0.050063</td>\n",
       "      <td>-0.139791</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389252</td>\n",
       "      <td>-0.185698</td>\n",
       "      <td>0.578363</td>\n",
       "      <td>-0.251025</td>\n",
       "      <td>-0.272333</td>\n",
       "      <td>0.281085</td>\n",
       "      <td>0.238651</td>\n",
       "      <td>-0.789375</td>\n",
       "      <td>-0.383446</td>\n",
       "      <td>-0.362789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>0.043814</td>\n",
       "      <td>0.720727</td>\n",
       "      <td>-1.287162</td>\n",
       "      <td>-0.669099</td>\n",
       "      <td>-0.243183</td>\n",
       "      <td>-0.291542</td>\n",
       "      <td>-0.142858</td>\n",
       "      <td>-0.050063</td>\n",
       "      <td>-0.139791</td>\n",
       "      <td>0.499271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389252</td>\n",
       "      <td>-0.185698</td>\n",
       "      <td>0.273816</td>\n",
       "      <td>0.578733</td>\n",
       "      <td>-0.250587</td>\n",
       "      <td>-0.272034</td>\n",
       "      <td>0.280600</td>\n",
       "      <td>0.238319</td>\n",
       "      <td>-0.789995</td>\n",
       "      <td>-0.383576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>0.116403</td>\n",
       "      <td>0.720727</td>\n",
       "      <td>-1.287162</td>\n",
       "      <td>-0.669099</td>\n",
       "      <td>-0.243183</td>\n",
       "      <td>-0.291542</td>\n",
       "      <td>-0.142858</td>\n",
       "      <td>-0.050063</td>\n",
       "      <td>-0.139791</td>\n",
       "      <td>0.998542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.639501</td>\n",
       "      <td>-0.185698</td>\n",
       "      <td>0.043414</td>\n",
       "      <td>0.274274</td>\n",
       "      <td>0.579122</td>\n",
       "      <td>-0.250289</td>\n",
       "      <td>-0.272395</td>\n",
       "      <td>0.280260</td>\n",
       "      <td>0.236160</td>\n",
       "      <td>-0.790135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>-0.218058</td>\n",
       "      <td>0.720727</td>\n",
       "      <td>-1.287162</td>\n",
       "      <td>-0.669099</td>\n",
       "      <td>-0.243183</td>\n",
       "      <td>-0.291542</td>\n",
       "      <td>-0.142858</td>\n",
       "      <td>-0.050063</td>\n",
       "      <td>7.147572</td>\n",
       "      <td>1.497814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.514377</td>\n",
       "      <td>-0.185698</td>\n",
       "      <td>0.116027</td>\n",
       "      <td>0.043939</td>\n",
       "      <td>0.274681</td>\n",
       "      <td>0.579390</td>\n",
       "      <td>-0.250655</td>\n",
       "      <td>-0.272619</td>\n",
       "      <td>0.278037</td>\n",
       "      <td>0.236045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>-1.049619</td>\n",
       "      <td>0.720727</td>\n",
       "      <td>-1.287162</td>\n",
       "      <td>-0.669099</td>\n",
       "      <td>-0.243183</td>\n",
       "      <td>-0.291542</td>\n",
       "      <td>-0.142858</td>\n",
       "      <td>-0.050063</td>\n",
       "      <td>7.147572</td>\n",
       "      <td>-1.497814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389252</td>\n",
       "      <td>-0.185698</td>\n",
       "      <td>-0.218546</td>\n",
       "      <td>0.116531</td>\n",
       "      <td>0.044359</td>\n",
       "      <td>0.274960</td>\n",
       "      <td>0.578838</td>\n",
       "      <td>-0.250884</td>\n",
       "      <td>-0.274014</td>\n",
       "      <td>0.277924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1199 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Steps  AD_Month  AH_Month  Long_Vacation  Short_Vacation   Ramadan  \\\n",
       "8     0.077199 -0.181938  0.650276       1.493300       -0.243183  3.427173   \n",
       "9    -0.415612 -0.181938  0.650276       1.493300       -0.243183  3.427173   \n",
       "10    2.442935 -0.181938  0.650276       1.493300       -0.243183  3.427173   \n",
       "11    2.048748 -0.181938  0.650276       1.493300       -0.243183  3.427173   \n",
       "12    1.979528 -0.181938  0.650276       1.493300       -0.243183  3.427173   \n",
       "...        ...       ...       ...            ...             ...       ...   \n",
       "1202  0.274140  0.720727 -1.287162      -0.669099       -0.243183 -0.291542   \n",
       "1203  0.043814  0.720727 -1.287162      -0.669099       -0.243183 -0.291542   \n",
       "1204  0.116403  0.720727 -1.287162      -0.669099       -0.243183 -0.291542   \n",
       "1205 -0.218058  0.720727 -1.287162      -0.669099       -0.243183 -0.291542   \n",
       "1206 -1.049619  0.720727 -1.287162      -0.669099       -0.243183 -0.291542   \n",
       "\n",
       "      Sch_Eid_Fatr  National_Day  National_Day_Ext  AD_WeekdayNum  ...  \\\n",
       "8        -0.142858     -0.050063         -0.139791       1.497814  ...   \n",
       "9        -0.142858     -0.050063         -0.139791      -1.497814  ...   \n",
       "10       -0.142858     -0.050063         -0.139791      -0.998542  ...   \n",
       "11       -0.142858     -0.050063         -0.139791      -0.499271  ...   \n",
       "12       -0.142858     -0.050063         -0.139791       0.000000  ...   \n",
       "...            ...           ...               ...            ...  ...   \n",
       "1202     -0.142858     -0.050063         -0.139791       0.000000  ...   \n",
       "1203     -0.142858     -0.050063         -0.139791       0.499271  ...   \n",
       "1204     -0.142858     -0.050063         -0.139791       0.998542  ...   \n",
       "1205     -0.142858     -0.050063          7.147572       1.497814  ...   \n",
       "1206     -0.142858     -0.050063          7.147572      -1.497814  ...   \n",
       "\n",
       "      temp_max   is_rain      Lag1      Lag2      Lag3      Lag4      Lag5  \\\n",
       "8     1.077436 -0.185698 -0.552813 -0.862393 -0.390251 -0.302354  0.780624   \n",
       "9     0.952312 -0.185698  0.076810 -0.552115 -0.861920 -0.389947 -0.302709   \n",
       "10    0.952312 -0.185698 -0.416165  0.077325 -0.551660 -0.861598 -0.390282   \n",
       "11    0.764625 -0.185698  2.443333 -0.415506  0.077743 -0.551350 -0.861828   \n",
       "12    0.639501 -0.185698  2.049015  2.443160 -0.415059  0.078030 -0.551649   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1202  0.389252 -0.185698  0.578363 -0.251025 -0.272333  0.281085  0.238651   \n",
       "1203  0.389252 -0.185698  0.273816  0.578733 -0.250587 -0.272034  0.280600   \n",
       "1204  0.639501 -0.185698  0.043414  0.274274  0.579122 -0.250289 -0.272395   \n",
       "1205  0.514377 -0.185698  0.116027  0.043939  0.274681  0.579390 -0.250655   \n",
       "1206  0.389252 -0.185698 -0.218546  0.116531  0.044359  0.274960  0.578838   \n",
       "\n",
       "          Lag6      Lag7      Lag8  \n",
       "8     0.916101  1.909126 -0.129858  \n",
       "9     0.780178  0.912927  1.909052  \n",
       "10   -0.302927  0.777207  0.912829  \n",
       "11   -0.390481 -0.304276  0.777105  \n",
       "12   -0.861929 -0.391699 -0.304404  \n",
       "...        ...       ...       ...  \n",
       "1202 -0.789375 -0.383446 -0.362789  \n",
       "1203  0.238319 -0.789995 -0.383576  \n",
       "1204  0.280260  0.236160 -0.790135  \n",
       "1205 -0.272619  0.278037  0.236045  \n",
       "1206 -0.250884 -0.274014  0.277924  \n",
       "\n",
       "[1199 rows x 22 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Norm_Merged=(Merged-Merged.mean())/Merged.std()\n",
    "Norm_Merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3574665525490285\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#features = [\"AD_Month\",\"AH_Month\",\"Long_Vacation\",\"Short_Vacation\",\"Ramadan\",\"Sch_Eid_Adha\",\"Sch_Eid_Fatr\",\"National_Day\",\"National_Day_ext\",\"AD_Weekdaynum\",\"Woke_Hour\"]\n",
    "\n",
    "\n",
    "y = Merged.iloc[:,:1]\n",
    "x_org = Merged.iloc[:,1:]\n",
    "x_org\n",
    "x = x_org.copy()\n",
    "#x = x.loc[:,[\"Lag1\",\"Lag2\",\"Lag3\",\"Lag4\",\"Lag5\",\"Lag6\",\"Lag7\",\"AD_WeekdayNum\",\"Long_Vacation\",\"Short_Vacation\",\"Ramadan\",\"National_Day_Ext\",\"Woke_Hour\"]].copy()\n",
    "x = x.loc[:,[\"Lag1\",\"Lag2\",\"Lag3\",\"Lag4\",\"Lag5\",\"Lag6\",\"Lag7\",\"Long_Vacation\",\"AD_Month\",\"temp_min\"]].copy()\n",
    "\n",
    "#del x['Sch_Eid_Adha']\n",
    "#del x['Sch_Eid_Fatr']\n",
    "#del x['National_Day']\n",
    "#del x['National_Day_Ext']\n",
    "#del x['Woke_Hour']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.3, random_state=42)\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train,y_train)\n",
    "print(lm.score(X_test,y_test))\n",
    "#y, X = patsy.dmatrices('Steps ~  AD_WeekdayNum', data=Merged, return_type=\"dataframe\")\n",
    "mean_absolute_error(lm.predict(X_test),y_test)\n",
    "# Create your model\n",
    "#model = sm.OLS(y, X)\n",
    "#lm.predict(X_test)\n",
    "# Fit your model to your training set\n",
    "#fit = model.fit()\n",
    "\n",
    "# Print summary statistics of the model's performance\n",
    "#fit.summary()\n",
    "preds = lm.predict(X_train) # generate predictions (on training data) using fit model\n",
    "\n",
    "sns.jointplot(x=preds,y=y_train, kind='reg')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -- Cross- Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# selected_columns =  Merged.loc[:,[\"Lag1\",\"Lag2\",\"Lag3\",\"Lag4\",\"Lag5\",\"Lag6\",\"Lag7\",\"Long_Vacation\",\"AD_Month\",\"temp_min\"]].copy()\n",
    "\n",
    "\n",
    "# y = selected_columns.iloc[:,:1]\n",
    "# x_org = selected_columns.iloc[:,1:]\n",
    "# selected_columns\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -- Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularization(X, y):\n",
    "    \n",
    "    # Grid Search\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    params = {'alpha': np.linspace(0.001, 100, num=100)}\n",
    "    model = GridSearchCV(Lasso(), param_grid=params, cv=kf, return_train_score=False)\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD_Month</td>\n",
       "      <td>37.946338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AH_Month</td>\n",
       "      <td>-29.527487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Long_Vacation</td>\n",
       "      <td>357.713226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Short_Vacation</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ramadan</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sch_Eid_Fatr</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>National_Day</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>National_Day_Ext</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AD_WeekdayNum</td>\n",
       "      <td>14.786014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Woke_Hour</td>\n",
       "      <td>-3.409241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>temp_min</td>\n",
       "      <td>17.779604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>temp_max</td>\n",
       "      <td>-18.263629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>is_rain</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lag1</td>\n",
       "      <td>0.272819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lag2</td>\n",
       "      <td>0.211010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Lag3</td>\n",
       "      <td>0.097003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Lag4</td>\n",
       "      <td>0.089098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Lag5</td>\n",
       "      <td>0.006707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Lag6</td>\n",
       "      <td>0.041087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Lag7</td>\n",
       "      <td>-0.008635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Lag8</td>\n",
       "      <td>0.022404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name        Coef\n",
       "0           AD_Month   37.946338\n",
       "1           AH_Month  -29.527487\n",
       "2      Long_Vacation  357.713226\n",
       "3     Short_Vacation   -0.000000\n",
       "4            Ramadan   -0.000000\n",
       "5       Sch_Eid_Fatr   -0.000000\n",
       "6       National_Day   -0.000000\n",
       "7   National_Day_Ext   -0.000000\n",
       "8      AD_WeekdayNum   14.786014\n",
       "9          Woke_Hour   -3.409241\n",
       "10          temp_min   17.779604\n",
       "11          temp_max  -18.263629\n",
       "12           is_rain   -0.000000\n",
       "13              Lag1    0.272819\n",
       "14              Lag2    0.211010\n",
       "15              Lag3    0.097003\n",
       "16              Lag4    0.089098\n",
       "17              Lag5    0.006707\n",
       "18              Lag6    0.041087\n",
       "19              Lag7   -0.008635\n",
       "20              Lag8    0.022404"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.35455582529900975"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = Merged.drop(['Steps'], axis=1)\n",
    "y = Merged['Steps']\n",
    "\n",
    "# Normal Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = regularization(X_train, y_train)\n",
    "model.predict(X_test)\n",
    "\n",
    "display(pd.DataFrame({'Name':X.columns, 'Coef':model.best_estimator_.coef_}))\n",
    "\n",
    "# Evaluation\n",
    "model.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score : 0.35455582529900975\n"
     ]
    }
   ],
   "source": [
    "# split X and y\n",
    "X = Merged.drop(['Steps'], axis=1)\n",
    "y = Merged['Steps']\n",
    "\n",
    "# kFold Grid Search\n",
    "model = regularization(X, y)\n",
    "\n",
    "# score model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "print(f'model score : {model.best_estimator_.score(X_test, y_test)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score : 0.3518932438952881\n"
     ]
    }
   ],
   "source": [
    "# eleminate columns with 0 coef, and retraining\n",
    "df = Merged.iloc[:,np.append([True], model.best_estimator_.coef_ != 0)]\n",
    "X = df.drop(['Steps'], axis=1)\n",
    "y = df['Steps']\n",
    "\n",
    "model_mini = regularization(X, y)\n",
    "\n",
    "# score model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "model_mini.fit(X_train, y_train)\n",
    "print(f'model score : {model_mini.best_estimator_.score(X_test, y_test)}')\n",
    "\n",
    "filename = 'finalized_model2.sav'\n",
    "pickle.dump(model_mini, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Steps</th>\n",
       "      <th>AD_Month</th>\n",
       "      <th>AH_Month</th>\n",
       "      <th>Long_Vacation</th>\n",
       "      <th>AD_WeekdayNum</th>\n",
       "      <th>Woke_Hour</th>\n",
       "      <th>temp_min</th>\n",
       "      <th>temp_max</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Lag6</th>\n",
       "      <th>Lag7</th>\n",
       "      <th>Lag8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3811</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>93</td>\n",
       "      <td>111</td>\n",
       "      <td>1756.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>2283.0</td>\n",
       "      <td>2569.0</td>\n",
       "      <td>6107.0</td>\n",
       "      <td>6551.0</td>\n",
       "      <td>9810.0</td>\n",
       "      <td>3140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2202</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>82</td>\n",
       "      <td>109</td>\n",
       "      <td>3811.0</td>\n",
       "      <td>1756.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>2283.0</td>\n",
       "      <td>2569.0</td>\n",
       "      <td>6107.0</td>\n",
       "      <td>6551.0</td>\n",
       "      <td>9810.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11535</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>81</td>\n",
       "      <td>109</td>\n",
       "      <td>2202.0</td>\n",
       "      <td>3811.0</td>\n",
       "      <td>1756.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>2283.0</td>\n",
       "      <td>2569.0</td>\n",
       "      <td>6107.0</td>\n",
       "      <td>6551.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10248</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>84</td>\n",
       "      <td>106</td>\n",
       "      <td>11535.0</td>\n",
       "      <td>2202.0</td>\n",
       "      <td>3811.0</td>\n",
       "      <td>1756.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>2283.0</td>\n",
       "      <td>2569.0</td>\n",
       "      <td>6107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10022</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>81</td>\n",
       "      <td>104</td>\n",
       "      <td>10248.0</td>\n",
       "      <td>11535.0</td>\n",
       "      <td>2202.0</td>\n",
       "      <td>3811.0</td>\n",
       "      <td>1756.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>2283.0</td>\n",
       "      <td>2569.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>4454</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>73</td>\n",
       "      <td>100</td>\n",
       "      <td>5448.0</td>\n",
       "      <td>2739.0</td>\n",
       "      <td>2668.0</td>\n",
       "      <td>4474.0</td>\n",
       "      <td>4337.0</td>\n",
       "      <td>980.0</td>\n",
       "      <td>2310.0</td>\n",
       "      <td>2378.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>3702</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>73</td>\n",
       "      <td>100</td>\n",
       "      <td>4454.0</td>\n",
       "      <td>5448.0</td>\n",
       "      <td>2739.0</td>\n",
       "      <td>2668.0</td>\n",
       "      <td>4474.0</td>\n",
       "      <td>4337.0</td>\n",
       "      <td>980.0</td>\n",
       "      <td>2310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>3939</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>77</td>\n",
       "      <td>104</td>\n",
       "      <td>3702.0</td>\n",
       "      <td>4454.0</td>\n",
       "      <td>5448.0</td>\n",
       "      <td>2739.0</td>\n",
       "      <td>2668.0</td>\n",
       "      <td>4474.0</td>\n",
       "      <td>4337.0</td>\n",
       "      <td>980.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>2847</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>77</td>\n",
       "      <td>102</td>\n",
       "      <td>3939.0</td>\n",
       "      <td>3702.0</td>\n",
       "      <td>4454.0</td>\n",
       "      <td>5448.0</td>\n",
       "      <td>2739.0</td>\n",
       "      <td>2668.0</td>\n",
       "      <td>4474.0</td>\n",
       "      <td>4337.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>132</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>77</td>\n",
       "      <td>100</td>\n",
       "      <td>2847.0</td>\n",
       "      <td>3939.0</td>\n",
       "      <td>3702.0</td>\n",
       "      <td>4454.0</td>\n",
       "      <td>5448.0</td>\n",
       "      <td>2739.0</td>\n",
       "      <td>2668.0</td>\n",
       "      <td>4474.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1199 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Steps  AD_Month  AH_Month  Long_Vacation  AD_WeekdayNum  Woke_Hour  \\\n",
       "8      3811         6         9              1              6          6   \n",
       "9      2202         6         9              1              0          6   \n",
       "10    11535         6         9              1              1         12   \n",
       "11    10248         6         9              1              2         10   \n",
       "12    10022         6         9              1              3         10   \n",
       "...     ...       ...       ...            ...            ...        ...   \n",
       "1202   4454         9         2              0              3          3   \n",
       "1203   3702         9         2              0              4          6   \n",
       "1204   3939         9         2              0              5          8   \n",
       "1205   2847         9         2              0              6          4   \n",
       "1206    132         9         2              0              0         23   \n",
       "\n",
       "      temp_min  temp_max     Lag1     Lag2    Lag3    Lag4    Lag5    Lag6  \\\n",
       "8           93       111   1756.0    743.0  2283.0  2569.0  6107.0  6551.0   \n",
       "9           82       109   3811.0   1756.0   743.0  2283.0  2569.0  6107.0   \n",
       "10          81       109   2202.0   3811.0  1756.0   743.0  2283.0  2569.0   \n",
       "11          84       106  11535.0   2202.0  3811.0  1756.0   743.0  2283.0   \n",
       "12          81       104  10248.0  11535.0  2202.0  3811.0  1756.0   743.0   \n",
       "...        ...       ...      ...      ...     ...     ...     ...     ...   \n",
       "1202        73       100   5448.0   2739.0  2668.0  4474.0  4337.0   980.0   \n",
       "1203        73       100   4454.0   5448.0  2739.0  2668.0  4474.0  4337.0   \n",
       "1204        77       104   3702.0   4454.0  5448.0  2739.0  2668.0  4474.0   \n",
       "1205        77       102   3939.0   3702.0  4454.0  5448.0  2739.0  2668.0   \n",
       "1206        77       100   2847.0   3939.0  3702.0  4454.0  5448.0  2739.0   \n",
       "\n",
       "        Lag7    Lag8  \n",
       "8     9810.0  3140.0  \n",
       "9     6551.0  9810.0  \n",
       "10    6107.0  6551.0  \n",
       "11    2569.0  6107.0  \n",
       "12    2283.0  2569.0  \n",
       "...      ...     ...  \n",
       "1202  2310.0  2378.0  \n",
       "1203   980.0  2310.0  \n",
       "1204  4337.0   980.0  \n",
       "1205  4474.0  4337.0  \n",
       "1206  2668.0  4474.0  \n",
       "\n",
       "[1199 rows x 16 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('is_rain', -0.0052751593886384285),\n",
       " ('temp_min', 0.008070591527205129),\n",
       " ('temp_max', 0.0018472179881753314),\n",
       " ('AD_Month', 0.006529392232651476),\n",
       " ('AH_Month', -0.0239820285048693),\n",
       " ('Long_Vacation', 0.028176756272644377),\n",
       " ('Short_Vacation', 0.003504125152054116),\n",
       " ('Ramadan', 0.008162157896928313),\n",
       " ('Sch_Eid_Adha', -0.004284802024396406),\n",
       " ('Sch_Eid_Fatr', 0.00370217457120936),\n",
       " ('National_Day', -0.0040274452651380965),\n",
       " ('National_Day_Ext', -0.001418733192048327),\n",
       " ('AD_WeekdayNum', -0.006381166636464819),\n",
       " ('Woke_Hour', -0.012088361021947103)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loop through each feature and log r squared\n",
    "rsq = []\n",
    "mse = []\n",
    "features = [\"is_rain\",\"temp_min\",\"temp_max\",\"AD_Month\",\"AH_Month\",\"Long_Vacation\",\"Short_Vacation\",\"Ramadan\",\"Sch_Eid_Adha\",\"Sch_Eid_Fatr\",\"National_Day\",\"National_Day_Ext\",\"AD_WeekdayNum\",\"Woke_Hour\"]\n",
    "for feature in features:\n",
    "    x = x_org.copy()\n",
    "    x = x.loc[:,[feature]].copy()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.3, random_state=42)\n",
    "\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(X_train,y_train)\n",
    "    rsq.append(lm.score(X_test,y_test))\n",
    "    mse.append(mean_absolute_error(lm.predict(X_test),y_test))\n",
    "    #y, X = patsy.dmatrices('Steps ~  AD_WeekdayNum', data=Merged, return_type=\"dataframe\")\n",
    "    \n",
    "list(zip(features,rsq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regression: 0.3550599776458464\n",
      "Gradient Boosted Regression: 0.3114289796892339\n"
     ]
    }
   ],
   "source": [
    "#trying random forest\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "rf = RandomForestRegressor(n_estimators=2000, max_features=3, max_depth=5)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print(\"Random Forest Regression:\", r2_score(y_test, y_pred))\n",
    "\n",
    "gbm = GradientBoostingRegressor(n_estimators=500, max_depth=3, learning_rate=.01)\n",
    "gbm.fit(X_train, y_train)\n",
    "y_pred = gbm.predict(X_test)\n",
    "print(\"Gradient Boosted Regression:\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Steps = Steps.dropna()\n",
    "y = Steps.iloc[:,1:2]\n",
    "x = Steps.iloc[:,2:]\n",
    "#split 800, the rest 407\n",
    "X_train = x[:800]\n",
    "X_test = x[800:]\n",
    "y_train = y[:800]\n",
    "y_test = y[800:]\n",
    "\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit(X_train,y_train)\n",
    "#print(X_test)\n",
    "score = lm.score(X_test,y_test)\n",
    "#y, X = patsy.dmatrices('Steps ~  AD_WeekdayNum', data=Merged, return_type=\"dataframe\")\n",
    "print(mean_absolute_error(lm.predict(X_test),y_test))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.predict(pd.DataFrame(columns=['Lag1'],data=[7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularization(X, y):\n",
    "\n",
    "    # Grid Search\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    params = {\"alpha\": np.linspace(0.001, 100, num=100)}\n",
    "    GS = GridSearchCV(Lasso(), param_grid=params, cv=kf, return_train_score=False)\n",
    "    GS.fit(X_train, y_train)\n",
    "    GS.best_estimator_.alpha\n",
    "    \n",
    "    return GS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AD_Month</th>\n",
       "      <th>AH_Month</th>\n",
       "      <th>Long_Vacation</th>\n",
       "      <th>Short_Vacation</th>\n",
       "      <th>Ramadan</th>\n",
       "      <th>Sch_Eid_Fatr</th>\n",
       "      <th>National_Day</th>\n",
       "      <th>National_Day_Ext</th>\n",
       "      <th>AD_WeekdayNum</th>\n",
       "      <th>Woke_Hour</th>\n",
       "      <th>...</th>\n",
       "      <th>temp_max</th>\n",
       "      <th>is_rain</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Lag6</th>\n",
       "      <th>Lag7</th>\n",
       "      <th>Lag8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>1.322504</td>\n",
       "      <td>-1.010386</td>\n",
       "      <td>-0.669099</td>\n",
       "      <td>-0.243183</td>\n",
       "      <td>-0.291542</td>\n",
       "      <td>-0.142858</td>\n",
       "      <td>-0.050063</td>\n",
       "      <td>-0.139791</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.917099</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.799428</td>\n",
       "      <td>-0.185698</td>\n",
       "      <td>1.053567</td>\n",
       "      <td>0.556373</td>\n",
       "      <td>1.440684</td>\n",
       "      <td>-0.091030</td>\n",
       "      <td>2.872882</td>\n",
       "      <td>-0.048223</td>\n",
       "      <td>-0.113840</td>\n",
       "      <td>-0.037236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>-1.686381</td>\n",
       "      <td>-0.456832</td>\n",
       "      <td>-0.669099</td>\n",
       "      <td>-0.243183</td>\n",
       "      <td>-0.291542</td>\n",
       "      <td>-0.142858</td>\n",
       "      <td>-0.050063</td>\n",
       "      <td>-0.139791</td>\n",
       "      <td>-0.499271</td>\n",
       "      <td>-0.917099</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.174801</td>\n",
       "      <td>-0.185698</td>\n",
       "      <td>0.213764</td>\n",
       "      <td>0.138584</td>\n",
       "      <td>-0.601889</td>\n",
       "      <td>-0.496834</td>\n",
       "      <td>-0.850499</td>\n",
       "      <td>-0.801008</td>\n",
       "      <td>0.512185</td>\n",
       "      <td>0.307881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1.021616</td>\n",
       "      <td>-1.563939</td>\n",
       "      <td>-0.669099</td>\n",
       "      <td>-0.243183</td>\n",
       "      <td>-0.291542</td>\n",
       "      <td>-0.142858</td>\n",
       "      <td>-0.050063</td>\n",
       "      <td>-0.139791</td>\n",
       "      <td>-1.497814</td>\n",
       "      <td>-0.917099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201566</td>\n",
       "      <td>-0.185698</td>\n",
       "      <td>0.230309</td>\n",
       "      <td>1.692121</td>\n",
       "      <td>-0.766361</td>\n",
       "      <td>-1.082111</td>\n",
       "      <td>0.213543</td>\n",
       "      <td>-0.310886</td>\n",
       "      <td>2.178121</td>\n",
       "      <td>0.259888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>1.623393</td>\n",
       "      <td>-0.733609</td>\n",
       "      <td>-0.669099</td>\n",
       "      <td>-0.243183</td>\n",
       "      <td>-0.291542</td>\n",
       "      <td>-0.142858</td>\n",
       "      <td>-0.050063</td>\n",
       "      <td>-0.139791</td>\n",
       "      <td>0.998542</td>\n",
       "      <td>0.424083</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.362488</td>\n",
       "      <td>-0.185698</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.191574</td>\n",
       "      <td>0.327667</td>\n",
       "      <td>0.584903</td>\n",
       "      <td>0.263760</td>\n",
       "      <td>0.753544</td>\n",
       "      <td>-0.640520</td>\n",
       "      <td>-0.735418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>-0.482827</td>\n",
       "      <td>0.650276</td>\n",
       "      <td>-0.669099</td>\n",
       "      <td>-0.243183</td>\n",
       "      <td>3.427173</td>\n",
       "      <td>-0.142858</td>\n",
       "      <td>-0.050063</td>\n",
       "      <td>-0.139791</td>\n",
       "      <td>-0.998542</td>\n",
       "      <td>-1.084747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.514377</td>\n",
       "      <td>-0.185698</td>\n",
       "      <td>-0.422905</td>\n",
       "      <td>-0.714758</td>\n",
       "      <td>-0.437418</td>\n",
       "      <td>-0.728066</td>\n",
       "      <td>-0.863053</td>\n",
       "      <td>-0.750802</td>\n",
       "      <td>-0.181088</td>\n",
       "      <td>-0.365235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>-0.783715</td>\n",
       "      <td>0.650276</td>\n",
       "      <td>-0.669099</td>\n",
       "      <td>-0.243183</td>\n",
       "      <td>3.427173</td>\n",
       "      <td>-0.142858</td>\n",
       "      <td>-0.050063</td>\n",
       "      <td>-0.139791</td>\n",
       "      <td>-1.497814</td>\n",
       "      <td>0.759379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201566</td>\n",
       "      <td>-0.185698</td>\n",
       "      <td>-0.981140</td>\n",
       "      <td>-0.578762</td>\n",
       "      <td>-0.867739</td>\n",
       "      <td>-0.721941</td>\n",
       "      <td>-0.043358</td>\n",
       "      <td>-0.981015</td>\n",
       "      <td>-0.432966</td>\n",
       "      <td>-0.560566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>-0.181938</td>\n",
       "      <td>0.927052</td>\n",
       "      <td>1.493300</td>\n",
       "      <td>-0.243183</td>\n",
       "      <td>-0.291542</td>\n",
       "      <td>-0.142858</td>\n",
       "      <td>-0.050063</td>\n",
       "      <td>-0.139791</td>\n",
       "      <td>-0.499271</td>\n",
       "      <td>-0.078860</td>\n",
       "      <td>...</td>\n",
       "      <td>1.077436</td>\n",
       "      <td>-0.185698</td>\n",
       "      <td>-0.847556</td>\n",
       "      <td>0.252833</td>\n",
       "      <td>-0.370649</td>\n",
       "      <td>0.820422</td>\n",
       "      <td>-0.510618</td>\n",
       "      <td>-0.904787</td>\n",
       "      <td>-0.383752</td>\n",
       "      <td>-0.917605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>0.118950</td>\n",
       "      <td>1.480606</td>\n",
       "      <td>1.493300</td>\n",
       "      <td>-0.243183</td>\n",
       "      <td>-0.291542</td>\n",
       "      <td>-0.142858</td>\n",
       "      <td>-0.050063</td>\n",
       "      <td>-0.139791</td>\n",
       "      <td>-0.499271</td>\n",
       "      <td>-0.414156</td>\n",
       "      <td>...</td>\n",
       "      <td>1.077436</td>\n",
       "      <td>-0.185698</td>\n",
       "      <td>-0.052485</td>\n",
       "      <td>-0.807566</td>\n",
       "      <td>-0.174324</td>\n",
       "      <td>-0.871093</td>\n",
       "      <td>0.777868</td>\n",
       "      <td>-0.985301</td>\n",
       "      <td>-0.757594</td>\n",
       "      <td>-0.823149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>1.021616</td>\n",
       "      <td>-1.287162</td>\n",
       "      <td>-0.669099</td>\n",
       "      <td>-0.243183</td>\n",
       "      <td>-0.291542</td>\n",
       "      <td>-0.142858</td>\n",
       "      <td>-0.050063</td>\n",
       "      <td>-0.139791</td>\n",
       "      <td>0.998542</td>\n",
       "      <td>-1.252394</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.173807</td>\n",
       "      <td>-0.185698</td>\n",
       "      <td>-0.581000</td>\n",
       "      <td>-0.196504</td>\n",
       "      <td>-0.627923</td>\n",
       "      <td>-0.136970</td>\n",
       "      <td>-0.490103</td>\n",
       "      <td>0.473737</td>\n",
       "      <td>0.765897</td>\n",
       "      <td>0.516051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>0.118950</td>\n",
       "      <td>1.203829</td>\n",
       "      <td>1.493300</td>\n",
       "      <td>-0.243183</td>\n",
       "      <td>-0.291542</td>\n",
       "      <td>-0.142858</td>\n",
       "      <td>-0.050063</td>\n",
       "      <td>-0.139791</td>\n",
       "      <td>0.998542</td>\n",
       "      <td>-0.078860</td>\n",
       "      <td>...</td>\n",
       "      <td>1.327685</td>\n",
       "      <td>-0.185698</td>\n",
       "      <td>0.777514</td>\n",
       "      <td>-0.985831</td>\n",
       "      <td>-0.756866</td>\n",
       "      <td>-0.822090</td>\n",
       "      <td>-0.434681</td>\n",
       "      <td>-0.847234</td>\n",
       "      <td>-0.260258</td>\n",
       "      <td>-0.828040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>839 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AD_Month  AH_Month  Long_Vacation  Short_Vacation   Ramadan  \\\n",
       "530   1.322504 -1.010386      -0.669099       -0.243183 -0.291542   \n",
       "221  -1.686381 -0.456832      -0.669099       -0.243183 -0.291542   \n",
       "128   1.021616 -1.563939      -0.669099       -0.243183 -0.291542   \n",
       "924   1.623393 -0.733609      -0.669099       -0.243183 -0.291542   \n",
       "1074 -0.482827  0.650276      -0.669099       -0.243183  3.427173   \n",
       "...        ...       ...            ...             ...       ...   \n",
       "1052 -0.783715  0.650276      -0.669099       -0.243183  3.427173   \n",
       "1103 -0.181938  0.927052       1.493300       -0.243183 -0.291542   \n",
       "1138  0.118950  1.480606       1.493300       -0.243183 -0.291542   \n",
       "868   1.021616 -1.287162      -0.669099       -0.243183 -0.291542   \n",
       "1134  0.118950  1.203829       1.493300       -0.243183 -0.291542   \n",
       "\n",
       "      Sch_Eid_Fatr  National_Day  National_Day_Ext  AD_WeekdayNum  Woke_Hour  \\\n",
       "530      -0.142858     -0.050063         -0.139791       0.000000  -0.917099   \n",
       "221      -0.142858     -0.050063         -0.139791      -0.499271  -0.917099   \n",
       "128      -0.142858     -0.050063         -0.139791      -1.497814  -0.917099   \n",
       "924      -0.142858     -0.050063         -0.139791       0.998542   0.424083   \n",
       "1074     -0.142858     -0.050063         -0.139791      -0.998542  -1.084747   \n",
       "...            ...           ...               ...            ...        ...   \n",
       "1052     -0.142858     -0.050063         -0.139791      -1.497814   0.759379   \n",
       "1103     -0.142858     -0.050063         -0.139791      -0.499271  -0.078860   \n",
       "1138     -0.142858     -0.050063         -0.139791      -0.499271  -0.414156   \n",
       "868      -0.142858     -0.050063         -0.139791       0.998542  -1.252394   \n",
       "1134     -0.142858     -0.050063         -0.139791       0.998542  -0.078860   \n",
       "\n",
       "      ...  temp_max   is_rain      Lag1      Lag2      Lag3      Lag4  \\\n",
       "530   ... -0.799428 -0.185698  1.053567  0.556373  1.440684 -0.091030   \n",
       "221   ... -1.174801 -0.185698  0.213764  0.138584 -0.601889 -0.496834   \n",
       "128   ...  0.201566 -0.185698  0.230309  1.692121 -0.766361 -1.082111   \n",
       "924   ... -1.362488 -0.185698  0.540984  0.191574  0.327667  0.584903   \n",
       "1074  ...  0.514377 -0.185698 -0.422905 -0.714758 -0.437418 -0.728066   \n",
       "...   ...       ...       ...       ...       ...       ...       ...   \n",
       "1052  ...  0.201566 -0.185698 -0.981140 -0.578762 -0.867739 -0.721941   \n",
       "1103  ...  1.077436 -0.185698 -0.847556  0.252833 -0.370649  0.820422   \n",
       "1138  ...  1.077436 -0.185698 -0.052485 -0.807566 -0.174324 -0.871093   \n",
       "868   ... -0.173807 -0.185698 -0.581000 -0.196504 -0.627923 -0.136970   \n",
       "1134  ...  1.327685 -0.185698  0.777514 -0.985831 -0.756866 -0.822090   \n",
       "\n",
       "          Lag5      Lag6      Lag7      Lag8  \n",
       "530   2.872882 -0.048223 -0.113840 -0.037236  \n",
       "221  -0.850499 -0.801008  0.512185  0.307881  \n",
       "128   0.213543 -0.310886  2.178121  0.259888  \n",
       "924   0.263760  0.753544 -0.640520 -0.735418  \n",
       "1074 -0.863053 -0.750802 -0.181088 -0.365235  \n",
       "...        ...       ...       ...       ...  \n",
       "1052 -0.043358 -0.981015 -0.432966 -0.560566  \n",
       "1103 -0.510618 -0.904787 -0.383752 -0.917605  \n",
       "1138  0.777868 -0.985301 -0.757594 -0.823149  \n",
       "868  -0.490103  0.473737  0.765897  0.516051  \n",
       "1134 -0.434681 -0.847234 -0.260258 -0.828040  \n",
       "\n",
       "[839 rows x 21 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define base model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(36, input_dim=21, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(16, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "y = Norm_Merged.iloc[:,:1]\n",
    "x_org = Norm_Merged.iloc[:,1:]\n",
    "x_org\n",
    "x = x_org.copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_org,y, test_size=0.3, random_state=42)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "168/168 [==============================] - 1s 1ms/step - loss: 11968237.0000\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 7680515.5000\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 7275579.0000\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 7204736.0000\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 7165311.0000\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 7185346.5000\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 7047812.5000\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 7202603.0000\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 7165091.5000\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 7020308.0000\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 7154620.5000\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 7140073.5000\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 7047879.0000\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 0s 1ms/step - loss: 7150641.5000\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 7098366.0000\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 7033919.5000\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 7074495.5000\n",
      "Epoch 18/1000\n",
      "140/168 [========================>.....] - ETA: 0s - loss: 6841388.000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-c3700c8781fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#print(\"Standardized: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKerasRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbaseline_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1187\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1189\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1190\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1191\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    433\u001b[0m     \"\"\"\n\u001b[0;32m    434\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unrecognized hook: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    313\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m       \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1026\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1028\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1029\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1099\u001b[0m       \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1101\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1103\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_finalize_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, current, values, finalize)\u001b[0m\n\u001b[0;32m    907\u001b[0m       \u001b[0mprev_total_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_total_width\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dynamic_display\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\b'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mprev_total_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    910\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    402\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m             \u001b[1;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 404\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    405\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m                 \u001b[1;31m# mp.Pool cannot be trusted to flush promptly (or ever),\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    203\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[1;31m# wake event thread (message content is ignored)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\zmq\\sugar\\socket.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[0;32m    398\u001b[0m                                  copy_threshold=self.copy_threshold)\n\u001b[0;32m    399\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_parts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=50, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "#kfold = KFold(n_splits=4)\n",
    "#results = cross_val_score(pipeline, x_org, y, cv=kfold)\n",
    "#print(\"Standardized: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n",
    "estimator = KerasRegressor(build_fn=baseline_model, epochs=1000, batch_size=5, verbose=1)\n",
    "estimator.fit(X_train,y_train)\n",
    "estimator.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: -7283363.50 (2941509.49) MSE\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=5)\n",
    "results = cross_val_score(estimator, x_org, y, cv=kfold)\n",
    "print(\"Baseline: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n",
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.8603 - val_loss: 0.7404\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.6621 - val_loss: 0.6891\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.6287 - val_loss: 0.6593\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.6074 - val_loss: 0.6508\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.5871 - val_loss: 0.6610\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.5789 - val_loss: 0.6460\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.5722 - val_loss: 0.6647\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - ETA: 0s - loss: 0.569 - 1s 4ms/step - loss: 0.5549 - val_loss: 0.6650\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5494 - val_loss: 0.6396\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5405 - val_loss: 0.6567\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5265 - val_loss: 0.6470\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5188 - val_loss: 0.6535\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5134 - val_loss: 0.6627\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.5029 - val_loss: 0.6671\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.4963 - val_loss: 0.6798\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.4730 - val_loss: 0.6914\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.4862 - val_loss: 0.6705\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.4771 - val_loss: 0.6694\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.4583 - val_loss: 0.6881\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.4516 - val_loss: 0.6817\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.4385 - val_loss: 0.7150\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.4361 - val_loss: 0.7179\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.4218 - val_loss: 0.6936\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.4212 - val_loss: 0.7252\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - ETA: 0s - loss: 0.402 - 0s 2ms/step - loss: 0.4059 - val_loss: 0.7819\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.4053 - val_loss: 0.7348\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.3857 - val_loss: 0.8035\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.3761 - val_loss: 0.7939\n",
      "Epoch 29/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.3808 - val_loss: 0.7808\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.3646 - val_loss: 0.7654\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.3520 - val_loss: 0.7705\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.3417 - val_loss: 0.7907\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.3557 - val_loss: 0.8974\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.3337 - val_loss: 0.7977\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.3312 - val_loss: 0.7862\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.3177 - val_loss: 0.7963\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.3085 - val_loss: 0.9894\n",
      "Epoch 38/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.3315 - val_loss: 0.7913\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.3048 - val_loss: 0.9045\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.3021 - val_loss: 0.9314\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.3014 - val_loss: 0.9155\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2900 - val_loss: 0.8461\n",
      "Epoch 43/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2855 - val_loss: 0.8708\n",
      "Epoch 44/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2802 - val_loss: 0.8503\n",
      "Epoch 45/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2750 - val_loss: 0.9635\n",
      "Epoch 46/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2787 - val_loss: 0.9083\n",
      "Epoch 47/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2628 - val_loss: 0.9223\n",
      "Epoch 48/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2528 - val_loss: 0.8703\n",
      "Epoch 49/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2636 - val_loss: 0.9533\n",
      "Epoch 50/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2720 - val_loss: 0.9223\n",
      "Epoch 51/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.2538 - val_loss: 0.9051\n",
      "Epoch 52/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2439 - val_loss: 0.9692\n",
      "Epoch 53/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.2342 - val_loss: 0.9146\n",
      "Epoch 54/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2458 - val_loss: 0.9519\n",
      "Epoch 55/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.2378 - val_loss: 0.9608\n",
      "Epoch 56/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2513 - val_loss: 1.0283\n",
      "Epoch 57/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2383 - val_loss: 1.0209\n",
      "Epoch 58/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2264 - val_loss: 0.9785\n",
      "Epoch 59/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2266 - val_loss: 0.9399\n",
      "Epoch 60/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2224 - val_loss: 0.9934\n",
      "Epoch 61/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.2189 - val_loss: 0.9595\n",
      "Epoch 62/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2156 - val_loss: 1.0321\n",
      "Epoch 63/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2054 - val_loss: 1.1122\n",
      "Epoch 64/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2158 - val_loss: 0.9894\n",
      "Epoch 65/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2088 - val_loss: 1.0967\n",
      "Epoch 66/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2102 - val_loss: 1.0075\n",
      "Epoch 67/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2098 - val_loss: 1.0082\n",
      "Epoch 68/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.2068 - val_loss: 1.0251\n",
      "Epoch 69/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1966 - val_loss: 0.9925\n",
      "Epoch 70/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 1.1478\n",
      "Epoch 71/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1970 - val_loss: 0.9811\n",
      "Epoch 72/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1967 - val_loss: 1.0228\n",
      "Epoch 73/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1950 - val_loss: 1.0656\n",
      "Epoch 74/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1833 - val_loss: 0.9827\n",
      "Epoch 75/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1851 - val_loss: 1.0633\n",
      "Epoch 76/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1782 - val_loss: 1.0523\n",
      "Epoch 77/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1822 - val_loss: 1.0448\n",
      "Epoch 78/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1842 - val_loss: 1.0444\n",
      "Epoch 79/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.1887 - val_loss: 1.1122\n",
      "Epoch 80/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1812 - val_loss: 1.0786\n",
      "Epoch 81/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1819 - val_loss: 1.1035\n",
      "Epoch 82/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.1691 - val_loss: 1.0598\n",
      "Epoch 83/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.1676 - val_loss: 1.0701\n",
      "Epoch 84/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.1690 - val_loss: 1.0816\n",
      "Epoch 85/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.1700 - val_loss: 1.0856\n",
      "Epoch 86/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1676 - val_loss: 1.1095\n",
      "Epoch 87/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.1670 - val_loss: 1.0589\n",
      "Epoch 88/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.1637 - val_loss: 1.1875\n",
      "Epoch 89/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.1643 - val_loss: 1.1199\n",
      "Epoch 90/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.1552 - val_loss: 1.1062\n",
      "Epoch 91/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1663 - val_loss: 1.1339\n",
      "Epoch 92/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1572 - val_loss: 1.0883\n",
      "Epoch 93/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1559 - val_loss: 1.1095\n",
      "Epoch 94/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1595 - val_loss: 1.0832\n",
      "Epoch 95/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1567 - val_loss: 1.1547\n",
      "Epoch 96/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1596 - val_loss: 1.1381\n",
      "Epoch 97/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1536 - val_loss: 1.1206\n",
      "Epoch 98/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1474 - val_loss: 1.1663\n",
      "Epoch 99/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1579 - val_loss: 1.1451\n",
      "Epoch 100/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1531 - val_loss: 1.1315\n",
      "Epoch 101/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1474 - val_loss: 1.1688\n",
      "Epoch 102/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1440 - val_loss: 1.2090\n",
      "Epoch 103/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1434 - val_loss: 1.1682\n",
      "Epoch 104/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1477 - val_loss: 1.1837\n",
      "Epoch 105/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1642 - val_loss: 1.1895\n",
      "Epoch 106/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1501 - val_loss: 1.1216\n",
      "Epoch 107/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1572 - val_loss: 1.2263\n",
      "Epoch 108/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1456 - val_loss: 1.1066\n",
      "Epoch 109/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1411 - val_loss: 1.1611\n",
      "Epoch 110/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1385 - val_loss: 1.1438\n",
      "Epoch 111/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1402 - val_loss: 1.1994\n",
      "Epoch 112/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1363 - val_loss: 1.1257\n",
      "Epoch 113/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1422 - val_loss: 1.2007\n",
      "Epoch 114/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1350 - val_loss: 1.1683\n",
      "Epoch 115/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1360 - val_loss: 1.2337\n",
      "Epoch 116/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1369 - val_loss: 1.1391\n",
      "Epoch 117/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1374 - val_loss: 1.1542\n",
      "Epoch 118/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1327 - val_loss: 1.2879\n",
      "Epoch 119/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1327 - val_loss: 1.1906\n",
      "Epoch 120/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1280 - val_loss: 1.2153\n",
      "Epoch 121/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1381 - val_loss: 1.1535\n",
      "Epoch 122/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1468 - val_loss: 1.1590\n",
      "Epoch 123/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1371 - val_loss: 1.1969\n",
      "Epoch 124/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1382 - val_loss: 1.1873\n",
      "Epoch 125/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1325 - val_loss: 1.1928\n",
      "Epoch 126/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1271 - val_loss: 1.2073\n",
      "Epoch 127/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1272 - val_loss: 1.2287\n",
      "Epoch 128/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1297 - val_loss: 1.2710\n",
      "Epoch 129/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1247 - val_loss: 1.1986\n",
      "Epoch 130/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1268 - val_loss: 1.2620\n",
      "Epoch 131/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1294 - val_loss: 1.1822\n",
      "Epoch 132/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1305 - val_loss: 1.2760\n",
      "Epoch 133/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1242 - val_loss: 1.2643\n",
      "Epoch 134/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1220 - val_loss: 1.2314\n",
      "Epoch 135/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1238 - val_loss: 1.2364\n",
      "Epoch 136/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1179 - val_loss: 1.2469\n",
      "Epoch 137/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1191 - val_loss: 1.2778\n",
      "Epoch 138/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1199 - val_loss: 1.1957\n",
      "Epoch 139/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1159 - val_loss: 1.3779\n",
      "Epoch 140/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1269 - val_loss: 1.3121\n",
      "Epoch 141/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1272 - val_loss: 1.2772\n",
      "Epoch 142/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1291 - val_loss: 1.2373\n",
      "Epoch 143/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1140 - val_loss: 1.2055\n",
      "Epoch 144/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1143 - val_loss: 1.2257\n",
      "Epoch 145/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.1146 - val_loss: 1.2024\n",
      "Epoch 146/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1239 - val_loss: 1.2850\n",
      "Epoch 147/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1200 - val_loss: 1.2768\n",
      "Epoch 148/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1162 - val_loss: 1.2054\n",
      "Epoch 149/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1115 - val_loss: 1.2635\n",
      "Epoch 150/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1170 - val_loss: 1.2877\n",
      "Epoch 151/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1106 - val_loss: 1.1806\n",
      "Epoch 152/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1107 - val_loss: 1.2205\n",
      "Epoch 153/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1107 - val_loss: 1.2590\n",
      "Epoch 154/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1088 - val_loss: 1.2497\n",
      "Epoch 155/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1140 - val_loss: 1.2259\n",
      "Epoch 156/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1078 - val_loss: 1.2110\n",
      "Epoch 157/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1134 - val_loss: 1.2175\n",
      "Epoch 158/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1163 - val_loss: 1.2366\n",
      "Epoch 159/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1119 - val_loss: 1.2684\n",
      "Epoch 160/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1119 - val_loss: 1.1908\n",
      "Epoch 161/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.1138 - val_loss: 1.2896\n",
      "Epoch 162/1000\n",
      "168/168 [==============================] - 1s 3ms/step - loss: 0.1065 - val_loss: 1.2918\n",
      "Epoch 163/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1041 - val_loss: 1.2904\n",
      "Epoch 164/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1044 - val_loss: 1.2823\n",
      "Epoch 165/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1050 - val_loss: 1.2628\n",
      "Epoch 166/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1067 - val_loss: 1.2784\n",
      "Epoch 167/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1067 - val_loss: 1.2140\n",
      "Epoch 168/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1153 - val_loss: 1.2277\n",
      "Epoch 169/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1083 - val_loss: 1.2948\n",
      "Epoch 170/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1047 - val_loss: 1.2833\n",
      "Epoch 171/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.1024 - val_loss: 1.3151\n",
      "Epoch 172/1000\n",
      "168/168 [==============================] - 0s 2ms/step - loss: 0.0958 - val_loss: 1.2316\n",
      "Epoch 173/1000\n",
      "168/168 [==============================] - 0s 3ms/step - loss: 0.1031 - val_loss: 1.2776\n",
      "Epoch 174/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.1007 - val_loss: 1.2120\n",
      "Epoch 175/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.1005 - val_loss: 1.3066\n",
      "Epoch 176/1000\n",
      "157/168 [===========================>..] - ETA: 0s - loss: 0.1088"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-7640d79ed97a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKerasRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbaseline_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1213\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[1;32m-> 1215\u001b[1;33m           val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m   1216\u001b[0m               \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1217\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1501\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    922\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "estimator = KerasRegressor(build_fn=baseline_model, epochs=1000, batch_size=5, verbose=1)\n",
    "estimator.fit(X_train,y_train,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Steps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.077199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.415612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.442935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.048748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.979528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>0.274140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>0.043814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>0.116403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>-0.218058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>-1.049619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1199 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Steps\n",
       "8     0.077199\n",
       "9    -0.415612\n",
       "10    2.442935\n",
       "11    2.048748\n",
       "12    1.979528\n",
       "...        ...\n",
       "1202  0.274140\n",
       "1203  0.043814\n",
       "1204  0.116403\n",
       "1205 -0.218058\n",
       "1206 -1.049619\n",
       "\n",
       "[1199 rows x 1 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(y*y.std())+y.mean()*y.std()\n",
    "#Norm_Merged=(Merged-Merged.mean())/Merged.std()\n",
    "#Norm_Merged\n",
    "y\n",
    "#(Merged['Steps'].mean()+ y) * Merged['Steps'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
